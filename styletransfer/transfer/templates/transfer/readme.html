{% extends 'base2.html' %}
{% load static %}
{% block content %}

<!-- Header -->
<div id="header">
	<!-- Inner -->
	<div class="inner">
		<header>

		</header>
	</div>
	<!-- Nav -->
	<nav id="nav">
		<ul>
			<li><a href="/home">Home</a></li>
			<li><a href="/main">Main</a></li>
			<li><a href="/facedetector">facedetect</a></li>
			<li><a href="/readme" style="color: #DF7366;">README</a></li>
			<li><a href="/developer">Developer</a></li>
		</ul>
	</nav>
</div>


<!-- Main -->
<div class="wrapper style1">

	<div class="container">
		<article id="main" class="special">
			<header>
				<h1 style="font-size:4em; font-weight: bold;">DeepLearning Project</h1>
				<h4 id="-vae-gan-">뉴럴 스타일 트랜스퍼 (🌆✖️🌉🔜🌃)</h4>
			</header>
			<a href="#" class="image featured"><img src="images/pic06.jpg" alt="" /></a>

			<h5 id="-version">🔷 version</h5>
			<ul>
				<li>python 👉 3.7.13</li>
				<li>tensorflow 👉 2.8.0</li>
				<li>keras 👉 2.8.0
				<br></li>
			</ul>
			<br>

			<h2 id="boldtitle">뉴럴 스타일 트랜스퍼(🌆✖️🌉🔜🌃)</h2>
			<br>
			<h3 id="boldtitle">🔷 개념</h3>
			<p>뉴럴 스타일 트랜스퍼는 타깃 이미지의 콘텐츠를 보존하면서 참조 이미지의 스타일을 타깃 이미지에 적용합니다:
			뉴럴 스타일 전송(Neural style transfer)은 세 개의 이미지, 즉 콘텐츠 이미지, 스타일 참조 이미지(유명한 화가의 작품 등)와 스타일을 원하는 입력 이미지를 혼합하여 입력 이미지가 콘텐츠 이미지처럼 보이지만 스타일 이미지의 스타일로 &quot;페인팅&quot;되도록 하는 최적화 기법이다.</p>
			<br>
			<h4 id="boldtitle">🔷 작동 원리</h4>
			<ol>
				<li>데이터 시각화</li>
				<li>기본 데이터 사전 처리/준비</li>
				<li>손실 함수 설정</li>
				<li>모델 만들기</li>
				<li>손실 기능에 최적화
				</li>
				<br>
			</ol><br>
			<h4 id="boldtitle">🔷 구체적인 개념</h4>
			<ul>
				<li>신속한 실행 — 운영을 즉시 평가하는 TensorFlow의 필수 프로그래밍 환경 사용</li>
				<li>신속한 실행에 대해 자세히 알아보기</li>
				<li>실제 작업 보기(많은 튜토리얼이 공동 작업실에서 실행 가능)</li>
				<li>Functional API를 사용하여 모델을 정의합니다. Functional API를 사용하여 필요한 중간 활성화에 액세스할 수 있는 모델의 서브셋을 구축합니다.</li>
				<li>사전 교육된 모델의 피쳐 맵 활용 — 사전 교육된 모델과 해당 피쳐 맵의 사용 방법 알아보기</li>
				<li>맞춤형 교육 루프 생성 - 입력 매개 변수와 관련하여 주어진 손실을 최소화하기 위해 최적화 도구를 설정하는 방법을 살펴봅니다.<br><h6 id="boldtitle">이러한 과정에서, 우리는 실용적인 경험을 쌓고 다음 개념을 중심으로 직관을 개발할 것입니다.</h6>
				</li>
				<br>
			</ul>
			<h4 id="boldtitle">🔷 모델 구축</h4>
			<p>VGG19를 로드하고 입력 텐서를 모델에 공급한다. 이를 통해 콘텐츠, 스타일 및 생성된 이미지의 피쳐 맵(그리고 그 이후에 콘텐츠 및 스타일 표현)을 추출할 수 있습니다. 
			우리는 책에서 사용한 대로 VGG19를 사용하였습니다. 또한 VGG19는 (ResNet, Inception 등과 비교하여) 비교적 단순한 모델이기 때문에 기능 맵은 실제로 스타일 전송에 더 잘 작동한다. 
			스타일 및 콘텐츠 기능 맵에 해당하는 중간 레이어에 액세스하기 위해 해당 출력을 얻고 Keras Functional API를 사용하여 원하는 출력 활성화로 모델을 정의한다. 
			Functional API를 통해 모델을 정의하면 입력과 출력을 정의할 수 있습니다.</p>
			<br>
			<h4 id="boldtitle">🔷 뉴럴 스타일 트랜스퍼는 다음과 같이 작동합니다.</h4>
			<ul>
				<li>Style Image가 Conv 레이어들을 거쳐 나온 Feature Map의 각 채널별 특징의 상관관계 값을 Style Loss값으로 정의</li>
				<li>Content Image가 Conv4 레이어를 거쳐 나온 Feature Map의 차이를 Content Loss 값으로 정의</li>
				<li>위 두 Loss값이 작아지도록 학습하여 New Image 만들어간다.</li>
			</ul>
			<hr>
			<br>
			<br>
			<br>
			<div class="row">
				<article class="col-4 col-12-mobile special">
					<header>
						<h3>🔷 타겟 이미지</h3>
					</header>
					<br>
					<a href="#" class="image featured"><img src="{% static 'images/target_dog.jpg'%}" style="height:23em;" alt="" /></a>
				</article>
				<article class="col-4 col-12-mobile special">
					<header>
						<h3>🔷 스타일 이미지</h3>
					</header>
						<br>
					<a href="#" class="image featured"><img src="{% static 'images/style_picasso.jpg'%}" style="height:23em;" alt="" /></a>
				</article>
				<article class="col-4 col-12-mobile special">
					<header>
						<h3>🔷 생성 이미지</h3>
					</header>
						<br>
					<a href="#" class="image featured"><img src="{% static 'images/result_dog.png'%}" style="height:23em;" alt="" /></a>
				</article>
			</div>
		</article>
	</div>
</div>


<!-- footer -->
<div id="footer">
	<div class="container">
	<!-- Copyright -->
		<div class="copyright">
			<ul class="menu">
				<li>&copy; Untitled. All rights reserved.</li><li>Design: Chcaine</li>
			</ul>
		</div>
	</div>
</div>

{% endblock %}